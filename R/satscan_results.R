# SaTScan Execution and Result Parsing
# Internal helpers for running SaTScan and parsing output

# Suppress R CMD check notes for NSE columns
utils::globalVariables(c("LOC_ID", "CLUSTER", "P_VALUE", "REL_RISK", "CLU_RR", "epid_link_id", "CLU_ODE", "id_char", "RR"))

#' Run SatScan Analysis
#'
#' Executes SatScan by calling the binary directly and parsing the output files.
#' Use `satscanr()` as the main entry point.
#'
#' @param work_dir Working directory with input files.
#' @param project_name Project name (default: "epid"). This matches the inputs CaseFile=epid.cas etc.
#' @param ss_location Path to the folder containing the SaTScan executable (Backwards compatibility param).
#' @param ss_batch Name of the SaTScan executable (Backwards compatibility param).
#' @param verbose Print output?
#' @return satscan result object
#' @keywords internal
run_satscan <- function(work_dir, project_name = "epid",
                        ss_location, ss_batch, verbose = FALSE) {
    if (verbose) message("Running SaTScan...")

    # 1. Resolve Binary Path
    # Combine location and batch name to get full path
    ss_bin <- file.path(ss_location, ss_batch)

    # Verify binary exists
    if (!file.exists(ss_bin)) {
        stop("SaTScan binary not found at: ", ss_bin)
    }

    # 2. Identify PRM file
    prm_file <- file.path(work_dir, paste0(project_name, ".prm"))
    if (!file.exists(prm_file)) {
        stop("PRM file not found at: ", prm_file)
    }

    # 3. Execute Binary
    tryCatch(
        {
            run_satscan_binary(prm_file, ss_bin, verbose = verbose)
        },
        error = function(e) {
            warning("SaTScan execution failed: ", e$message)
            return(NULL)
        }
    )

    # 4. Parse Output Files
    read_satscan_files(work_dir, project_name, verbose = verbose)
}

#' Read SaTScan Output Files
#'
#' Reads the output files (.col.dbf, .gis.dbf, etc.) generated by a SaTScan run.
#' This replaces `rsatscan`'s file reading logic.
#'
#' @param out_dir Directory where output files are located.
#' @param project_name Base name of the project (e.g. "epid").
#' @param verbose Logical.
#' @return A list mimicking the structure of `rsatscan` output for compatibility.
#' @keywords internal
read_satscan_files <- function(out_dir, project_name, verbose = FALSE) {
    # Helper for reading DBF if it exists
    read_dbf_safe <- function(suffix) {
        f <- file.path(out_dir, paste0(project_name, suffix))
        if (file.exists(f)) {
            # Use sf::st_read for DBF (it handles it well without 'foreign' dependency if sf is installed)
            # Or suppress warnings about "no geometry"
            tryCatch(
                suppressMessages(sf::st_read(f, quiet = TRUE)),
                error = function(e) NULL
            )
        } else {
            NULL
        }
    }

    # Helper for reading Shapefile
    read_shp_safe <- function(suffix_no_ext) {
        # sf expects path to .shp or folder
        f <- file.path(out_dir, paste0(project_name, suffix_no_ext))
        if (file.exists(f) || file.exists(paste0(f, ".shp"))) {
            tryCatch(
                suppressMessages(sf::st_read(f, quiet = !verbose)),
                error = function(e) NULL
            )
        } else {
            NULL
        }
    }

    if (verbose) message("Reading SaTScan output files from: ", out_dir)

    # Read components
    # .col.dbf - Cluster information
    col_df <- read_dbf_safe(".col.dbf")

    # .gis.dbf - Location information
    gis_df <- read_dbf_safe(".gis.dbf")

    # .rr.dbf - Relative risks
    rr_df <- read_dbf_safe(".rr.dbf")

    # .sci.dbf - Cluster information (secondary?)
    sci_df <- read_dbf_safe(".sci.dbf")

    # .llr.dbf - Log likelihood ratios
    llr_df <- read_dbf_safe(".llr.dbf")

    # Shapefile (.col.shp)
    shapeclust <- read_shp_safe(".col")

    # Main text output - we don't usually parse this in R but handy to have the path
    txt_file <- file.path(out_dir, paste0(project_name, ".txt"))
    main_txt <- if (file.exists(txt_file)) txt_file else NA

    # Construct list similar to rsatscan object
    res <- list(
        main = main_txt,
        col = col_df,
        rr = rr_df,
        gis = gis_df,
        llr = llr_df,
        sci = sci_df,
        shapeclust = shapeclust,
        prm = NULL # We could read the prm text here but satscanr object already separates it
    )

    # Clean up DBF columns if needed (sometimes sf reads them as factors or adds geometry col if empty)
    # Usually sf::st_read on a DBF returns a data.frame (or tbl_df).
    # If it returns sf object with empty geometry, drop it.

    clean_df <- function(df) {
        if (inherits(df, "sf")) sf::st_drop_geometry(df) else df
    }

    res$col <- clean_df(res$col)
    res$gis <- clean_df(res$gis)
    res$rr <- clean_df(res$rr)
    res$sci <- clean_df(res$sci)
    res$llr <- clean_df(res$llr)

    return(res)
}

#' Get macOS SatScan Path
#'
#' Handles macOS App Bundle path detection
#'
#' @param ss_full_path Full path to SatScan executable
#' @return List with ss_location and ss_batch
#' @keywords internal
get_macos_satscan_path <- function(ss_full_path) {
    ss_location <- dirname(ss_full_path)
    ss_batch <- basename(ss_full_path)

    # macOS App Bundle handling - use CLI binary, not GUI launcher
    if (Sys.info()["sysname"] == "Darwin" && ss_batch == "SaTScan") {
        if (basename(ss_location) == "MacOS") {
            alt_location <- file.path(dirname(ss_location), "app")
            alt_batch <- "satscan"
            if (file.exists(file.path(alt_location, alt_batch))) {
                ss_location <- alt_location
                ss_batch <- alt_batch
            }
        }
    }

    list(ss_location = ss_location, ss_batch = ss_batch)
}

#' Parse SatScan Output into S3 Object
#'
#' Creates a satscan_result S3 object independent of the original data frame's structure (tidy/long),
#' allowing for efficient storage and flexible access to location-summaries.
#'
#' @param ss_results Result from run_satscan()
#' @param data Original input data (tibble/df/sf)
#' @param geo_df Geometry data frame (id, lat, long) matching data rows
#' @param id_quo Quosure for ID column
#' @param output_dir Output directory (optional)
#' @param verbose Print debug info?
#' @param merge_time_series Logical. If TRUE, creates a huge joined data frame in user memory?
#'   Defaults to FALSE to save memory.
#' @return object of class "satscan_result"
#' @keywords internal
parse_satscan_output <- function(ss_results, data, geo_df, id_quo, output_dir = NULL,
                                 verbose = FALSE, merge_time_series = FALSE) {
    # 1. Handle NULL results (no clusters or error)
    if (is.null(ss_results) || (is.null(ss_results$gis) && is.null(ss_results$col))) {
        if (verbose) message("No SaTScan results found (or parse failed).")
        res <- list(
            main_results = NULL,
            location_summary = NULL,
            cluster_summary = NULL,
            raw_output = ss_results
        )
        class(res) <- "satscan_result"
        return(res)
    }

    if (verbose) message("Parsing SaTScan results...")

    # 2. Create Cluster Summary (metadata for each cluster)
    # ss_results$col contains: CLUSTER, LOCATION_IDs, START_DATE, END_DATE, P_VALUE, etc.
    # It is usually the authoritative source for cluster-level stats.
    if (!is.null(ss_results$col)) {
        cluster_summary <- ss_results$col

        # Ensure standardized column names
        if ("RR" %in% names(cluster_summary) && !"REL_RISK" %in% names(cluster_summary)) {
            cluster_summary <- dplyr::rename(cluster_summary, REL_RISK = RR)
        }
    } else {
        # Fallback: Extract from GIS if COL file is missing
        if (verbose && !is.null(ss_results$gis)) message("No .col file found - extracting cluster summary from GIS data")
        if (!is.null(ss_results$gis)) {
            cluster_summary <- ss_results$gis |>
                dplyr::select(CLUSTER, P_VALUE, REL_RISK = CLU_RR, ODE = CLU_ODE) |>
                dplyr::distinct(CLUSTER, .keep_all = TRUE) |>
                dplyr::arrange(CLUSTER)
        } else {
            cluster_summary <- data.frame()
        }
    }

    # 3. Create Location Summary (One row per location)
    # Join unique geometry with GIS results
    # geo_df has duplicated rows (time series), so we distinct it
    loc_geo <- geo_df |>
        dplyr::distinct(id, .keep_all = TRUE)

    is_sf_input <- inherits(data, "sf")

    if (!is.null(ss_results$gis) && is.data.frame(ss_results$gis)) {
        gis_df <- ss_results$gis |>
            dplyr::mutate(LOC_ID = as.character(LOC_ID))

        location_summary <- loc_geo |>
            dplyr::left_join(gis_df, by = c("id" = "LOC_ID"))
    } else {
        # No GIS results - just return location info with NAs for stats
        location_summary <- loc_geo
    }

    # Restore sf if input was sf
    if (is_sf_input) {
        location_summary <- sf::st_as_sf(location_summary, coords = c("long", "lat"), crs = 4326)
    }

    # 4. Create Main Results (Optional Time Series Join)
    main_results <- NULL
    if (merge_time_series && !is.null(ss_results$gis)) {
        if (verbose) message("Merging results back to full time-series data...")
        # Map ID -> Cluster
        id_cluster_map <- gis_df |>
            dplyr::select(id = LOC_ID, CLUSTER, P_VALUE)

        # We drop geometry from data if it's sf, to keep main_results lightweight
        data_no_geo <- if (inherits(data, "sf")) sf::st_drop_geometry(data) else data

        main_results <- data_no_geo |>
            dplyr::mutate(id_char = as.character(dplyr::pull(data_no_geo, !!id_quo))) |>
            dplyr::left_join(id_cluster_map, by = c("id_char" = "id")) |>
            dplyr::select(-id_char)
    }

    # 5. Construct Object
    res <- list(
        main_results = main_results,
        location_summary = location_summary,
        cluster_summary = cluster_summary,
        raw_output = ss_results
    )
    class(res) <- "satscan_result"

    res
}

#' @export
print.satscan_result <- function(x, ...) {
    n_locs <- if (is.null(x$location_summary)) 0 else nrow(x$location_summary)
    n_clusters <- if (is.null(x$cluster_summary)) 0 else nrow(x$cluster_summary)
    # Check if P_VALUE exists in cluster_summary before subsetting
    has_p <- !is.null(x$cluster_summary) && "P_VALUE" %in% names(x$cluster_summary)
    sig_clusters <- if (n_clusters > 0 && has_p) sum(x$cluster_summary$P_VALUE < 0.05, na.rm = TRUE) else 0

    cat("SaTScan Analysis Result\n")
    cat("=======================\n")
    cat(sprintf("Locations: %d\n", n_locs))
    cat(sprintf("Clusters Found: %d (%d significant at p < 0.05)\n", n_clusters, sig_clusters))
    cat("\nTop Significant Clusters:\n")
    if (n_clusters > 0) {
        print(head(x$cluster_summary |>
            dplyr::filter(P_VALUE < 0.05) |>
            dplyr::select(dplyr::any_of(c("CLUSTER", "P_VALUE", "rel_risk", "REL_RISK", "START_DATE", "END_DATE"))), 5))
    } else {
        cat("None.\n")
    }
    cat("\nAccess components via $location_summary, $cluster_summary, $main_results\n")
}

#' @export
summary.satscan_result <- function(object, ...) {
    object$cluster_summary
}

#' @export
as.data.frame.satscan_result <- function(x, row.names = NULL, optional = FALSE, ...) {
    # If main_results (time series) is populated, user probably wants that.
    # If not, they probably want the location summary (map data).
    if (!is.null(x$main_results)) {
        return(x$main_results)
    } else {
        # If location_summary is SF, drop geometry to return a plain data.frame
        if (inherits(x$location_summary, "sf")) {
            return(sf::st_drop_geometry(x$location_summary))
        }
        return(x$location_summary)
    }
}
